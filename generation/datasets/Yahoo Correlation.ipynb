{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, csv, datetime\n",
    "from vadetisweb.utils.anomaly_detection_utils import next_later_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "\n",
    "yahoo_path = '/home/adrian/Dokumente/real_data/ydata-labeled-time-series-anomalies-v1_0'\n",
    "\n",
    "a1_path = '/A1Benchmark/'\n",
    "a2_path = '/A2Benchmark/'\n",
    "a3_path = '/A3Benchmark/'\n",
    "a4_path = '/A4Benchmark/'\n",
    "\n",
    "a1_elements = np.arange(1, 68).tolist()\n",
    "a234_elements = np.arange(1, 101).tolist()\n",
    "\n",
    "a1files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a1_path + 'real_' + str(x) + '.csv' } for x in a1_elements]\n",
    "a2files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a2_path + 'synthetic_' + str(x) + '.csv' } for x in a234_elements]\n",
    "a3files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a3_path + 'A3Benchmark-TS' + str(x) + '.csv' } for x in a234_elements]\n",
    "a4files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a4_path + 'A4Benchmark-TS' + str(x) + '.csv' } for x in a234_elements]\n",
    "\n",
    "#output\n",
    "output_path = '/home/adrian/Dokumente/real_data/yahoo_out2'\n",
    "\n",
    "test_file_name = output_path + a1_path + 'test.csv'\n",
    "train_file_name = output_path + a1_path + 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(ts_name, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.insert(0, 'ts_name', ts_name)\n",
    "    df.insert(2, 'unit', \"Value\")\n",
    "    df = df.rename(columns={'timestamp': 'time', 'is_anomaly' : 'class'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame_values_only(ts_name, file_path, drop_columns):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    df = df.rename(columns={'value': ts_name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_index_to_dt(df):\n",
    "    date_time_str = '2020-04-01 00:00:00'\n",
    "    dt = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S')\n",
    "    for idx, row in df.iterrows():\n",
    "        time_index = row['time']\n",
    "        dt = next_later_dt(dt, '1H')\n",
    "        df.loc[idx, 'time'] = dt\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_file(outputfile):\n",
    "    with open(outputfile, 'w') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        header = ['ts_name', 'time', 'unit', 'value', 'class']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "def append_to_file(df, outputfile):\n",
    "    with open(outputfile, 'a') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        for index, row in df.iterrows():\n",
    "            row = [row[0], row[1].isoformat(), row[2], row[3], row[4]]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1 set\n",
    "names_set_a1 = ['TS' + str(x) for x in np.arange(1,68).tolist()]\n",
    "\n",
    "# S2 set\n",
    "names_set_a2 = ['TS' + str(x) for x in np.arange(1,101).tolist()]\n",
    "names_set_a2 = ['TS' + str(x) for x in [24, 66, 3, 10, 45, 17, 87, 73, 31, 38]]\n",
    "\n",
    "# S3 set\n",
    "names_set_a3 = ['TS' + str(x) for x in np.arange(1,101).tolist()]\n",
    "\n",
    "# S4 set\n",
    "names_set_a4 = ['TS' + str(x) for x in np.arange(1,101).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlation(files, path, drop_columns):\n",
    "    df_concat = None\n",
    "    for entry in files:\n",
    "        ts_name = entry['name']\n",
    "        \n",
    "        if ts_name in names_set_a2:\n",
    "            file_path = entry['file_path']\n",
    "            df = load_data_frame_values_only(ts_name, file_path, drop_columns)\n",
    "            if df_concat is None:\n",
    "                df_concat = df\n",
    "            else:\n",
    "                df_concat = pd.concat([df_concat, df], axis=1)\n",
    "    #df_concat = df_concat[0:1001]\n",
    "    df_corr = df_concat.corr()\n",
    "    df_corr = df_corr.round(2)\n",
    "    #df_corr.to_csv(path +'corr.csv', index = True, header=True)\n",
    "    \n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_a1 = generate_correlation(a1files, output_path + a1_path, ['timestamp', 'is_anomaly'])\n",
    "df_corr_a2 = generate_correlation(a2files, output_path + a2_path, ['timestamp', 'is_anomaly'])\n",
    "df_corr_a3 = generate_correlation(a3files, output_path + a3_path, ['timestamps', 'anomaly', 'changepoint', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3'])\n",
    "df_corr_a4 = generate_correlation(a4files, output_path + a4_path, ['timestamps', 'anomaly', 'changepoint', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8919999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_a2 = generate_correlation(a2files, output_path + a2_path, ['timestamp', 'is_anomaly'])\n",
    "df_corr_a2.values[np.triu_indices_from(df_corr_a2.values,1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
